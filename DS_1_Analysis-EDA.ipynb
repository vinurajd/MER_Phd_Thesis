{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "360cea99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "\n",
    "# utilities\n",
    "from IPython.display import Markdown as md\n",
    "import librosa\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# stats\n",
    "from scipy.stats import norm\n",
    "\n",
    "#Clustering models\n",
    "from sklearn.cluster import KMeans\n",
    "from kneed import KneeLocator\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f651df7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize common variables\n",
    "num_trials = 20\n",
    "seed_value = 123467\n",
    "\n",
    "# set random seed\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "############################## Raw Data ##########################################################\n",
    "# read the dataset - based on the outcome of data processing & basic feature engineering\n",
    "# Set file paths\n",
    "root_path = \"D:/PhD Program/Final Research/Dissertation/Data/Model Datasets/\"\n",
    "data_file_path = root_path + \"DS_1_Feature_MFCC_no_hilbert_trans.csv\"\n",
    "os.chdir(root_path)\n",
    "\n",
    "feat_df = pd.read_csv(data_file_path)\n",
    "\n",
    "# Inital class variable\n",
    "y_char,unique_vals = pd.factorize(feat_df['sound_file_class'], sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17faf4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA 1: Extract key features and its correponding value ranges\n",
    "\n",
    "cols_format_to_extract = ['f0','plp','power','rms','spect_centroid','spect_rolloff','spect_flat','spect_bw','spect_contrast',\n",
    "                          'tempo','zcr']\n",
    "#measure_names = ['mean','median','max','min','sd','iqr']\n",
    "measure_names = ['mean','median','max','min']\n",
    "class_names = [1,2,3,4]\n",
    "class_name_dict = {'Q1':1,\n",
    "                  'Q2':2,\n",
    "                  'Q3':3,\n",
    "                  'Q4':4}\n",
    "#feat_summary_df = pd.DataFrame(columns = ['class','feature','mean','median','max','sd','iqr'])\n",
    "feat_summary_df = pd.DataFrame(columns = ['class','feature','mean','median','max'])\n",
    "cols_to_ignore = []\n",
    "for i in range(len(class_names)):\n",
    "    #print(i+1)\n",
    "    for key, val in class_name_dict.items():\n",
    "        if val == i+1:\n",
    "            class_val = key\n",
    "            \n",
    "    eda_df = feat_df[feat_df.sound_file_class==class_val]\n",
    "    for col_name in cols_format_to_extract:\n",
    "        val_ranges = []\n",
    "        for measure_val in measure_names:\n",
    "            #print(final_col_name)\n",
    "            final_col_name = str(col_name)+\"_\"+measure_val\n",
    "            try:\n",
    "                min_val = round(np.min(eda_df[final_col_name]),3)\n",
    "            except Exception as e:\n",
    "                min_val = 0\n",
    "            try:\n",
    "                max_val = round(np.max(eda_df[final_col_name]),3)\n",
    "            except Exception as e:\n",
    "                max_val = 0\n",
    "                \n",
    "            if min_val == max_val:\n",
    "                cols_to_ignore.append(final_col_name)\n",
    "            val_range = str(min_val) + \" - \"+ str(max_val)\n",
    "            val_ranges.append(val_range)\n",
    "\n",
    "        dict_tmp = {'feature':col_name,\n",
    "                    'class':class_val,\n",
    "                    'mean':val_ranges[0],\n",
    "                    'median':val_ranges[1],\n",
    "                    'max':val_ranges[2]}\n",
    "        \n",
    "    #print(dict_tmp)\n",
    "        feat_summary_df = feat_summary_df.append(dict_tmp, ignore_index=True)\n",
    "\n",
    "# Identity range of values for each feature in each class\n",
    "#print(cols_to_ignore)\n",
    "feat_summary_df.to_csv(root_path+\"feature_summary.csv\",index=False)\n",
    "#feat_summary_df\n",
    "cols_to_ignore = list(set(cols_to_ignore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22ba406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EAD 2: plot normal distribution curve for mean value of core features \n",
    "\n",
    "figure, axis = plt.subplots(6, 2, figsize= (20,30))\n",
    "full_feat_cols = [['f0_mean','plp_mean','power_mean','rms_mean','spect_centroid_mean','spect_rolloff_mean'],\n",
    "                 ['spect_flat_mean','spect_bw_mean','spect_contrast_mean','tempo_mean','zcr_mean']]\n",
    "\n",
    "# class - validate class overlap\n",
    "color_vals = ['blue','purple','green','gold']\n",
    "#mean_cols = list(X_means.columns)\n",
    "feat_col_cnt = 0\n",
    "for feat_cols in full_feat_cols:\n",
    "    #print(feat_cols)\n",
    "    row_cnt = 0\n",
    "    for col_val in feat_cols:\n",
    "        #print(col_val)\n",
    "        cntr=0\n",
    "        norm_df = feat_df[['sound_file_class',col_val]]\n",
    "\n",
    "        for class_val in unique_vals:\n",
    "            #print(class_val)\n",
    "            class_df = norm_df[norm_df.sound_file_class==class_val]\n",
    "            #print(class_df.head())\n",
    "            mean_val = np.mean(class_df[col_val])\n",
    "            sd_val = np.std(class_df[col_val])\n",
    "            x = class_df[col_val]\n",
    "            x_val = np.arange(max(x)*-1,max(x),0.001)\n",
    "            label_val = str(class_val)+\": N(\"+str(round(mean_val,1))+\",\"+str(round(sd_val,1))+\")\"\n",
    "            axis[row_cnt,feat_col_cnt].plot(x_val,norm.pdf(x_val,mean_val,sd_val),label = label_val, color=color_vals[cntr])    \n",
    "\n",
    "            #plt.plot(x_val,norm.pdf(x_val,mean_val,sd_val),label = label_val, color=color_vals[cntr])    \n",
    "            cntr +=1\n",
    "        axis[row_cnt,feat_col_cnt].legend()\n",
    "        axis[row_cnt,feat_col_cnt].set_ylabel(\"Density\")\n",
    "        axis[row_cnt,feat_col_cnt].set_xlabel(str(col_val))\n",
    "        axis[row_cnt,feat_col_cnt].set_title(\"Normal Distributions - \"+str(col_val))\n",
    "        row_cnt +=1\n",
    "    feat_col_cnt+=1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9eca07",
   "metadata": {},
   "source": [
    "Comments:\n",
    "1 Normal distribution plots indicate that there is significant class overlap between the classes Q3 and Q4\n",
    "2 This class overlap can yield to lower accuracy in the model since the model may not be able to determine class boundaries\n",
    "3 Kernel methods can be deployed to perform boundary detection but may not elevate the accuracy.\n",
    "4 From a emotion detection stand point, this indicates 2 aspects:\n",
    "    a Either the anotation of data was highly subjective OR\n",
    "    b This overlap clearly indicates the bias involved where the detection of emotion boundaries varies with \n",
    "    the characterestics of each human brain. In addition, the classes Q3 and Q4 can be interpreted to be \n",
    "    inclined towards the \"Sad\" emotion as per Russel's Circumplex Model: (https://www.researchgate.net/profile/Jukka-Haekkinen/publication/262981399/figure/fig3/AS:392492835983380@1470588992866/Russells-circumplex-model-of-emotion.png).\n",
    "\n",
    "Based on this perception, the class labels were re-classified into a ordinal variable with \n",
    "    a. \"1\" representing class \"Q1\"\n",
    "    b. \"2\" representing class \"Q2\" and \n",
    "    c. \"3\" representing class \"Q3\" and \"Q4\".\n",
    "\n",
    "In order to validate the 3 level re-classification of dependent variable, clustering (KMeans) is performed on the data to determine optimal clusters (elbow method) in the dataset using. MeanShift is also used as an additional method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1275b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA 3: Kmeans cluster to validate classes\n",
    "\n",
    "#figure, axis = plt.subplots(6, 2, figsize= (20,30))\n",
    "\n",
    "X = feat_df[['f0_mean','rms_mean','sound_file_class_num']]\n",
    "X_class = X[X.sound_file_class_num==1]\n",
    "x = X_class.f0_mean\n",
    "y_class = X_class.rms_mean\n",
    "plt.scatter(x,y_class,color=\"gray\", label=\"Q1\")\n",
    "X_class = X[X.sound_file_class_num==2]\n",
    "x = X_class.f0_mean\n",
    "y_class = X_class.rms_mean\n",
    "plt.scatter(x,y_class,color=\"green\", label=\"Q2\")\n",
    "X_class = X[X.sound_file_class_num==3]\n",
    "x = X_class.f0_mean\n",
    "y_class = X_class.rms_mean\n",
    "plt.scatter(x,y_class,color=\"blue\", label=\"Q3\")\n",
    "X_class = X[X.sound_file_class_num==4]\n",
    "x = X_class.f0_mean\n",
    "y_class = X_class.rms_mean\n",
    "plt.scatter(x,y_class,color=\"yellow\", label=\"Q4\")\n",
    "\n",
    "plt.plot(figsize=(20,30))\n",
    "plt.ylabel(\"rms\")\n",
    "plt.xlabel(\"F0 - Fundamental Fequency\")\n",
    "plt.title(\"F0 vs rms\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "sse_cluster = []\n",
    "for k in range(1,11,1):\n",
    "    k_means_model = KMeans(n_clusters = k).fit(X)\n",
    "    sse_cluster.append(k_means_model.inertia_)\n",
    "plt.plot(range(1,11,1),sse_cluster)\n",
    "plt.ylabel(\"sse\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.title(\"# of clusters\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Find elbow locator\n",
    "l1 = KneeLocator(range(1,11), sse_cluster, curve='convex',direction = 'decreasing')\n",
    "l1.elbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10611c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "md(\"Number of optimal clusters within the dataset are: {} clusters\".format(l1.elbow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa573a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA 4: Meanshift clustering to validate clusters\n",
    "from sklearn.cluster import MeanShift\n",
    "\n",
    "clust_model  = MeanShift(bandwidth=65).fit(X)\n",
    "print(clust_model)\n",
    " \n",
    "# SSpectralClustering(affinity='rbf', assign_labels='kmeans', coef0=1, degree=3,\n",
    "#                    eigen_solver=None, eigen_tol=0.0, gamma=1.0,\n",
    "#                    kernel_params=None, n_clusters=4, n_components=None,\n",
    "#                    n_init=10, n_jobs=None, n_neighbors=10, random_state=None)\n",
    "\n",
    "labels = clust_model.labels_\n",
    "print(set(labels))\n",
    "#plt.scatter(x[:,0], x[:,1], c=labels)\n",
    "x = X.f0_mean\n",
    "y_class = X.rms_mean\n",
    "plt.scatter(x,y_class,c=labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c269de8",
   "metadata": {},
   "source": [
    "-- Start the modelling\n",
    "Start with AdaBoost\n",
    "    - Determine optimal parameters using Grid Search\n",
    "    - Once the optimal parameters are found, determine the model robustness using \n",
    "      multiple samples drawn from the train dataset and validating it against a test\n",
    "      dataset which is extracted and kept as anonymous to the training process\n",
    "    - Repeat the above steps for 6 different datasets viz. \n",
    "       1. raw dataset with full features, \n",
    "       2. hilbert transformed dataset with full features\n",
    "       3. raw dataset with only \"mean\" features\n",
    "       4. hilbert transformed data with only \"mean\" features\n",
    "       5. raw dataset with a subset of \"mean\"features and \n",
    "       6. hilbert transformed data with a subset of \"mean\"features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
