{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38d01326",
   "metadata": {},
   "source": [
    "This script succeeds DS_1_Feature_Extraction.py and generates all necessary datasets needed for modelling based the following factors:\n",
    "\n",
    "*- MFCC features: Yes, No\n",
    "\n",
    "*- Data Scaling: Yes, No\n",
    "\n",
    "*- Anomaly treatment: Yes, No\n",
    "\n",
    "*- Hilbert Transformed: Yes, No\n",
    "\n",
    "*- Features: All Features, Mean features and mean subset\n",
    "\n",
    "*- Sound sample duration: All sound( 30 seconds), 5 seconds, 1 second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0689a9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# utilitity functions to build the datasets\n",
    "\n",
    "def scale_dataset(data_df):\n",
    "    scaler_obj = MinMaxScaler(feature_range=(0, 1))\n",
    "    numeric_col_df = data_df.select_dtypes(include='number')\n",
    "    numeric_col_df = numeric_col_df.fillna(0)\n",
    "    numeric_col_df_scaled = scaler_obj.fit(numeric_col_df)\n",
    "    numeric_col_df_scaled = pd.DataFrame(numeric_col_df_scaled.transform(numeric_col_df), columns = numeric_col_df.columns)\n",
    "    non_numeric_cols = set(list(numeric_col_df_scaled.columns)) ^ set(list(data_df.columns))\n",
    "    data_df_scaled = data_df[non_numeric_cols]\n",
    "    data_df_scaled = pd.concat([data_df_scaled,numeric_col_df_scaled], axis=1).reset_index(drop=True)\n",
    "    return data_df_scaled\n",
    "\n",
    "def ignore_columns_in_dataset(data_df, str_pattern=\"\"):\n",
    "    data_df_refined = data_df.loc[:,~data_df.columns.str.contains(str_pattern.strip())]\n",
    "    return data_df_refined\n",
    "\n",
    "def include_columns_in_dataset(data_df, class_var_name, str_pattern=\"\"):\n",
    "    data_df_refined = data_df[class_var_name]\n",
    "    data_df_include = data_df.loc[:,data_df.columns.str.contains(str_pattern.strip())]\n",
    "    data_df_refined = pd.concat([data_df_refined,data_df_include], axis=1)\n",
    "    return data_df_refined\n",
    "\n",
    "def eliminate_irrelevant_columns_in_dataset(data_df):\n",
    "    data_size = data_df.shape[0]\n",
    "    cols_to_ignore = []\n",
    "    max_val = 0\n",
    "    min_val = 0\n",
    "    # eliminate all numeric columns containing constant values - either all columns contains 0 or same value\n",
    "    # i.e. the min value of the column == max value in the column\n",
    "    numeric_df = data_df.select_dtypes(include='number')\n",
    "    numeric_df = numeric_df.fillna(0)\n",
    "    col_list = numeric_df.columns\n",
    "    non_numeric_cols = set(list(data_df.columns)) ^ set(list(numeric_df.columns))\n",
    "    col_df = data_df[non_numeric_cols]\n",
    "    \n",
    "    for col_name in col_list:\n",
    "        try:\n",
    "            min_val = np.min(numeric_df[col_name])\n",
    "        except Exception as e:\n",
    "            min_val = 0\n",
    "        \n",
    "        try:\n",
    "            max_val = np.max(numeric_df[col_name])\n",
    "        except Exception as e:\n",
    "            max_val = 0\n",
    "        \n",
    "        if min_val==max_val:\n",
    "            cols_to_ignore.append(col_name)\n",
    "        else:\n",
    "            # if the number of unique values is less than 5% of the data size(N), ignore the column\n",
    "            num_unique_vals_in_col = len(set(list(base_df[col_name])))\n",
    "            uniqueness_ratio = 1-(num_unique_vals_in_col/data_size)\n",
    "            if uniqueness_ratio > 0.95:\n",
    "                cols_to_ignore.append(col_name)\n",
    "    \n",
    "    dressed_df = numeric_df\n",
    "    if len(cols_to_ignore) > 0:\n",
    "        dressed_df = numeric_df[numeric_df.columns[~numeric_df.columns.isin(cols_to_ignore)]]\n",
    "    \n",
    "    dressed_df = pd.concat([col_df,dressed_df], axis=1)\n",
    "    dressed_df = dressed_df.fillna(0)\n",
    "    return dressed_df, cols_to_ignore\n",
    "\n",
    "def standardize_data(x):\n",
    "    mean_val = np.mean(x)\n",
    "    sd_val = np.std(x)\n",
    "    return (x - mean_val)/sd_val\n",
    "\n",
    "def treat_anomaly(data_df):\n",
    "    imputed_df = pd.DataFrame()\n",
    "    class_list = list(set(list(data_df.sound_file_class)))\n",
    "    for class_name in class_list:\n",
    "        # process one column at a time for each class\n",
    "        class_df = base_df[base_df.sound_file_class==class_name]\n",
    "        anomaly_df = class_df.select_dtypes(include='number')\n",
    "        anomaly_df.fillna(0)\n",
    "        col_list = anomaly_df.columns\n",
    "        non_numeric_cols = set(list(class_df.columns)) ^ set(list(anomaly_df.columns))\n",
    "        col_df = class_df[non_numeric_cols]\n",
    "        for col_name in col_list:\n",
    "            temp_df = anomaly_df[[col_name]]\n",
    "            temp_df['stand'] = temp_df.apply(lambda x: standardize_data(x))\n",
    "            temp_df['anomaly_flag'] = temp_df['stand'].apply(lambda x: 'N' if abs(x) < 3 else 'Y')\n",
    "            mean_val = np.mean(temp_df[col_name])\n",
    "            temp_df[col_name+\"_imputed\"] = temp_df.apply(lambda x: mean_val if x.anomaly_flag=='Y' else x[col_name], axis=1)\n",
    "            col_df = pd.concat([col_df,temp_df[col_name+\"_imputed\"]], axis=1)\n",
    "            col_df.rename(columns={col_name+\"_imputed\":col_name}, inplace=True)\n",
    "        imputed_df = pd.concat([imputed_df,col_df], axis=0)\n",
    "    return imputed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d3f993d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Feature Dataset with 4 classes & Sample Duration: Whole sound signal (30 seconds): (based dataset to use:DS_1_Feature_MFCC_hilbert_trans.csv)\n",
    "# 1.         Hilbert Transformed - Yes, MFCC included: Yes , Scale Data: No, Anomaly treated: No\n",
    "base_df = pd.read_csv(\"Data\\DS_1_Feature_MFCC_hilbert_trans.csv\")\n",
    "base_df,col_ignored = eliminate_irrelevant_columns_in_dataset(base_df)\n",
    "base_df.to_csv(\"Data\\Model Datasets\\DS_1_All_Feature_30_sec_yMFCC_yht_ns_nat.csv\", index=False)\n",
    "\n",
    "# # 2.         Hilbert Transformed - Yes, MFCC included: Yes , Scale Data: No, Anomaly treated: Yes\n",
    "anomaly_df = treat_anomaly(base_df)\n",
    "anomaly_df,col_ignored = eliminate_irrelevant_columns_in_dataset(anomaly_df)\n",
    "anomaly_df.to_csv(\"Data\\Model Datasets\\DS_1_All_Feature_30_sec_yMFCC_yht_ns_yat.csv\", index=False)\n",
    "\n",
    "# 3.         Hilbert Transformed - Yes, MFCC included: Yes ,  Scale Data: Yes, Anomaly treated: No\n",
    "scaled_df = scale_dataset(base_df)\n",
    "scaled_df,col_ignored = eliminate_irrelevant_columns_in_dataset(scaled_df)\n",
    "scaled_df.to_csv(\"Data\\Model Datasets\\DS_1_All_Feature_30_sec_yMFCC_yht_ys_nat.csv\", index=False)\n",
    "\n",
    "# # 4.         Hilbert Transformed - Yes, MFCC included: Yes , Scale Data: Yes, Anomaly treated: Yes\n",
    "scaled_df = scale_dataset(base_df)\n",
    "anomaly_df = treat_anomaly(scaled_df)\n",
    "anomaly_df,col_ignored = eliminate_irrelevant_columns_in_dataset(anomaly_df)\n",
    "anomaly_df.to_csv(\"Data\\Model Datasets\\DS_1_All_Feature_30_sec_yMFCC_yht_ys_yat.csv\", index=False)\n",
    "\n",
    "# 5.         Hilbert Transformed - Yes, MFCC included: No ,  Scale Data: No, Anomaly treated: No\n",
    "no_mfcc_base_df = ignore_columns_in_dataset(base_df,str_pattern=\"mfcc_\")\n",
    "no_mfcc_df,col_ignored = eliminate_irrelevant_columns_in_dataset(no_mfcc_base_df)\n",
    "no_mfcc_df.to_csv(\"Data\\Model Datasets\\DS_1_All_Feature_30_sec_nMFCC_yht_ns_nat.csv\", index=False)\n",
    "\n",
    "# 6.         Hilbert Transformed - Yes, MFCC included: No ,  Scale Data: Yes, Anomaly treated: No\n",
    "scaled_df = scale_dataset(no_mfcc_base_df)\n",
    "scaled_df,col_ignored = eliminate_irrelevant_columns_in_dataset(scaled_df)\n",
    "scaled_df.to_csv(\"Data\\Model Datasets\\DS_1_All_Feature_30_sec_nMFCC_yht_ys_nat.csv\", index=False)\n",
    "\n",
    "# 7.         Hilbert Transformed - Yes, MFCC included: No ,  Scale Data: No, Anomaly treated: Yes\n",
    "anomaly_df = treat_anomaly(no_mfcc_base_df)\n",
    "anomaly_df,col_ignored = eliminate_irrelevant_columns_in_dataset(anomaly_df)\n",
    "anomaly_df.to_csv(\"Data\\Model Datasets\\DS_1_All_Feature_30_sec_nMFCC_yht_ns_yat.csv\", index=False)\n",
    "\n",
    "# 8.         Hilbert Transformed - Yes, MFCC included: No ,  Scale Data: Yes, Anomaly treated: Yes\n",
    "scaled_df = scale_dataset(no_mfcc_base_df)\n",
    "anomaly_df = treat_anomaly(scaled_df)\n",
    "anomaly_df,col_ignored = eliminate_irrelevant_columns_in_dataset(anomaly_df)\n",
    "anomaly_df.to_csv(\"Data\\Model Datasets\\DS_1_All_Feature_30_sec_nMFCC_yht_ys_yat.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ba15782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Feature Dataset with 4 classes & Sample Duration: Whole sound signal (30 seconds): (based dataset to use:DS_1_Feature_MFCC_no_hilbert_trans.csv)\n",
    "# 1.         Hilbert Transformed - No, MFCC included: Yes , Scale Data: No, Anomaly treated: No\n",
    "base_df = pd.read_csv(\"Data\\DS_1_Feature_MFCC_no_hilbert_trans.csv\")\n",
    "base_df,col_ignored = eliminate_irrelevant_columns_in_dataset(base_df)\n",
    "base_df.to_csv(\"Data\\Model Datasets\\DS_1_All_Feature_30_sec_yMFCC_nht_ns_nat.csv\", index=False)\n",
    "\n",
    "# # 2.         Hilbert Transformed - No, MFCC included: Yes , Scale Data: No, Anomaly treated: Yes\n",
    "anomaly_df = treat_anomaly(base_df)\n",
    "anomaly_df,col_ignored = eliminate_irrelevant_columns_in_dataset(anomaly_df)\n",
    "anomaly_df.to_csv(\"Data\\Model Datasets\\DS_1_All_Feature_30_sec_yMFCC_nht_ns_yat.csv\", index=False)\n",
    "\n",
    "# 3.         Hilbert Transformed - No, MFCC included: Yes ,  Scale Data: Yes, Anomaly treated: No\n",
    "scaled_df = scale_dataset(base_df)\n",
    "scaled_df,col_ignored = eliminate_irrelevant_columns_in_dataset(scaled_df)\n",
    "scaled_df.to_csv(\"Data\\Model Datasets\\DS_1_All_Feature_30_sec_yMFCC_nht_ys_nat.csv\", index=False)\n",
    "\n",
    "# # 4.         Hilbert Transformed - No, MFCC included: Yes , Scale Data: Yes, Anomaly treated: Yes\n",
    "scaled_df = scale_dataset(base_df)\n",
    "anomaly_df = treat_anomaly(scaled_df)\n",
    "anomaly_df,col_ignored = eliminate_irrelevant_columns_in_dataset(anomaly_df)\n",
    "anomaly_df.to_csv(\"Data\\Model Datasets\\DS_1_All_Feature_30_sec_yMFCC_nht_ys_yat.csv\", index=False)\n",
    "\n",
    "# 5.         Hilbert Transformed - No, MFCC included: No ,  Scale Data: No, Anomaly treated: No\n",
    "no_mfcc_base_df = ignore_columns_in_dataset(base_df,str_pattern=\"mfcc_\")\n",
    "no_mfcc_df,col_ignored = eliminate_irrelevant_columns_in_dataset(no_mfcc_base_df)\n",
    "no_mfcc_df.to_csv(\"Data\\Model Datasets\\DS_1_All_Feature_30_sec_nMFCC_nht_ns_nat.csv\", index=False)\n",
    "\n",
    "# 6.         Hilbert Transformed - No, MFCC included: No ,  Scale Data: Yes, Anomaly treated: No\n",
    "scaled_df = scale_dataset(no_mfcc_base_df)\n",
    "scaled_df,col_ignored = eliminate_irrelevant_columns_in_dataset(scaled_df)\n",
    "scaled_df.to_csv(\"Data\\Model Datasets\\DS_1_All_Feature_30_sec_nMFCC_nht_ys_nat.csv\", index=False)\n",
    "\n",
    "# 7.         Hilbert Transformed - No, MFCC included: No ,  Scale Data: No, Anomaly treated: Yes\n",
    "anomaly_df = treat_anomaly(no_mfcc_base_df)\n",
    "anomaly_df,col_ignored = eliminate_irrelevant_columns_in_dataset(anomaly_df)\n",
    "anomaly_df.to_csv(\"Data\\Model Datasets\\DS_1_All_Feature_30_sec_nMFCC_nht_ns_yat.csv\", index=False)\n",
    "\n",
    "# 8.         Hilbert Transformed - No, MFCC included: No ,  Scale Data: Yes, Anomaly treated: Yes\n",
    "scaled_df = scale_dataset(no_mfcc_base_df)\n",
    "anomaly_df = treat_anomaly(scaled_df)\n",
    "anomaly_df,col_ignored = eliminate_irrelevant_columns_in_dataset(anomaly_df)\n",
    "anomaly_df.to_csv(\"Data\\Model Datasets\\DS_1_All_Feature_30_sec_nMFCC_nht_ys_yat.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a1e4e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Feature Dataset with 4 classes & Sample Duration: augmented sound signal (5 seconds): (based dataset to use:DS_1_Feature_MFCC_hilbert_trans.csv)\n",
    "# 1.         Hilbert Transformed - Yes, MFCC included: Yes , Scale Data: No, Anomaly treated: No\n",
    "base_df = pd.read_csv(\"Data\\DS_1_Feature_MFCC_hilbert_trans_ms_5sec.csv\")\n",
    "base_df,col_ignored = eliminate_irrelevant_columns_in_dataset(base_df)\n",
    "base_df.to_csv(\"Data\\Model Datasets\\DS_1_All_Feature_5_sec_yMFCC_yht_ns_nat.csv\", index=False)\n",
    "\n",
    "# # 2.         Hilbert Transformed - Yes, MFCC included: Yes , Scale Data: No, Anomaly treated: Yes\n",
    "anomaly_df = treat_anomaly(base_df)\n",
    "anomaly_df,col_ignored = eliminate_irrelevant_columns_in_dataset(anomaly_df)\n",
    "anomaly_df.to_csv(\"Data\\Model Datasets\\DS_1_All_Feature_5_sec_yMFCC_yht_ns_yat.csv\", index=False)\n",
    "\n",
    "# 3.         Hilbert Transformed - Yes, MFCC included: Yes ,  Scale Data: Yes, Anomaly treated: No\n",
    "scaled_df = scale_dataset(base_df)\n",
    "scaled_df,col_ignored = eliminate_irrelevant_columns_in_dataset(scaled_df)\n",
    "scaled_df.to_csv(\"Data\\Model Datasets\\DS_1_All_Feature_5_sec_yMFCC_yht_ys_nat.csv\", index=False)\n",
    "\n",
    "# # 4.         Hilbert Transformed - Yes, MFCC included: Yes , Scale Data: Yes, Anomaly treated: Yes\n",
    "scaled_df = scale_dataset(base_df)\n",
    "anomaly_df = treat_anomaly(scaled_df)\n",
    "anomaly_df,col_ignored = eliminate_irrelevant_columns_in_dataset(anomaly_df)\n",
    "anomaly_df.to_csv(\"Data\\Model Datasets\\DS_1_All_Feature_5_sec_yMFCC_yht_ys_yat.csv\", index=False)\n",
    "\n",
    "# 5.         Hilbert Transformed - Yes, MFCC included: No ,  Scale Data: No, Anomaly treated: No\n",
    "no_mfcc_base_df = ignore_columns_in_dataset(base_df,str_pattern=\"mfcc_\")\n",
    "no_mfcc_df,col_ignored = eliminate_irrelevant_columns_in_dataset(no_mfcc_base_df)\n",
    "no_mfcc_df.to_csv(\"Data\\Model Datasets\\DS_1_All_Feature_5_sec_nMFCC_yht_ns_nat.csv\", index=False)\n",
    "\n",
    "# 6.         Hilbert Transformed - Yes, MFCC included: No ,  Scale Data: Yes, Anomaly treated: No\n",
    "scaled_df = scale_dataset(no_mfcc_base_df)\n",
    "scaled_df,col_ignored = eliminate_irrelevant_columns_in_dataset(scaled_df)\n",
    "scaled_df.to_csv(\"Data\\Model Datasets\\DS_1_All_Feature_5_sec_nMFCC_yht_ys_nat.csv\", index=False)\n",
    "\n",
    "# 7.         Hilbert Transformed - Yes, MFCC included: No ,  Scale Data: No, Anomaly treated: Yes\n",
    "anomaly_df = treat_anomaly(no_mfcc_base_df)\n",
    "anomaly_df,col_ignored = eliminate_irrelevant_columns_in_dataset(anomaly_df)\n",
    "anomaly_df.to_csv(\"Data\\Model Datasets\\DS_1_All_Feature_5_sec_nMFCC_yht_ns_yat.csv\", index=False)\n",
    "\n",
    "# 8.         Hilbert Transformed - Yes, MFCC included: No ,  Scale Data: Yes, Anomaly treated: Yes\n",
    "scaled_df = scale_dataset(no_mfcc_base_df)\n",
    "anomaly_df = treat_anomaly(scaled_df)\n",
    "anomaly_df,col_ignored = eliminate_irrelevant_columns_in_dataset(anomaly_df)\n",
    "anomaly_df.to_csv(\"Data\\Model Datasets\\DS_1_All_Feature_5_sec_nMFCC_yht_ys_yat.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e86fc8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Feature Dataset with 4 classes & Sample Duration: augmented sound signal (5 seconds): (based dataset to use:DS_1_Feature_MFCC_no_hilbert_trans_ms_5sec.csv)\n",
    "# 1.         Hilbert Transformed - No, MFCC included: Yes , Scale Data: No, Anomaly treated: No\n",
    "base_df = pd.read_csv(\"Data\\DS_1_Feature_MFCC_no_hilbert_trans_ms_5sec.csv\")\n",
    "base_df,col_ignored = eliminate_irrelevant_columns_in_dataset(base_df)\n",
    "base_df.to_csv(\"Data\\Model Datasets\\DS_1_All_Feature_5_sec_yMFCC_nht_ns_nat.csv\", index=False)\n",
    "\n",
    "# # 2.         Hilbert Transformed - No, MFCC included: Yes , Scale Data: No, Anomaly treated: Yes\n",
    "anomaly_df = treat_anomaly(base_df)\n",
    "anomaly_df,col_ignored = eliminate_irrelevant_columns_in_dataset(anomaly_df)\n",
    "anomaly_df.to_csv(\"Data\\Model Datasets\\DS_1_All_Feature_5_sec_yMFCC_nht_ns_yat.csv\", index=False)\n",
    "\n",
    "# 3.         Hilbert Transformed - No, MFCC included: Yes ,  Scale Data: Yes, Anomaly treated: No\n",
    "scaled_df = scale_dataset(base_df)\n",
    "scaled_df,col_ignored = eliminate_irrelevant_columns_in_dataset(scaled_df)\n",
    "scaled_df.to_csv(\"Data\\Model Datasets\\DS_1_All_Feature_5_sec_yMFCC_nht_ys_nat.csv\", index=False)\n",
    "\n",
    "# # 4.         Hilbert Transformed - No, MFCC included: Yes , Scale Data: Yes, Anomaly treated: Yes\n",
    "scaled_df = scale_dataset(base_df)\n",
    "anomaly_df = treat_anomaly(scaled_df)\n",
    "anomaly_df,col_ignored = eliminate_irrelevant_columns_in_dataset(anomaly_df)\n",
    "anomaly_df.to_csv(\"Data\\Model Datasets\\DS_1_All_Feature_5_sec_yMFCC_nht_ys_yat.csv\", index=False)\n",
    "\n",
    "# 5.         Hilbert Transformed - No, MFCC included: No ,  Scale Data: No, Anomaly treated: No\n",
    "no_mfcc_base_df = ignore_columns_in_dataset(base_df,str_pattern=\"mfcc_\")\n",
    "no_mfcc_df,col_ignored = eliminate_irrelevant_columns_in_dataset(no_mfcc_base_df)\n",
    "no_mfcc_df.to_csv(\"Data\\Model Datasets\\DS_1_All_Feature_5_sec_nMFCC_nht_ns_nat.csv\", index=False)\n",
    "\n",
    "# 6.         Hilbert Transformed - No, MFCC included: No ,  Scale Data: Yes, Anomaly treated: No\n",
    "scaled_df = scale_dataset(no_mfcc_base_df)\n",
    "scaled_df,col_ignored = eliminate_irrelevant_columns_in_dataset(scaled_df)\n",
    "scaled_df.to_csv(\"Data\\Model Datasets\\DS_1_All_Feature_5_sec_nMFCC_nht_ys_nat.csv\", index=False)\n",
    "\n",
    "# 7.         Hilbert Transformed - No, MFCC included: No ,  Scale Data: No, Anomaly treated: Yes\n",
    "anomaly_df = treat_anomaly(no_mfcc_base_df)\n",
    "anomaly_df,col_ignored = eliminate_irrelevant_columns_in_dataset(anomaly_df)\n",
    "anomaly_df.to_csv(\"Data\\Model Datasets\\DS_1_All_Feature_5_sec_nMFCC_nht_ns_yat.csv\", index=False)\n",
    "\n",
    "# 8.         Hilbert Transformed - No, MFCC included: No ,  Scale Data: Yes, Anomaly treated: Yes\n",
    "scaled_df = scale_dataset(no_mfcc_base_df)\n",
    "anomaly_df = treat_anomaly(scaled_df)\n",
    "anomaly_df,col_ignored = eliminate_irrelevant_columns_in_dataset(anomaly_df)\n",
    "anomaly_df.to_csv(\"Data\\Model Datasets\\DS_1_All_Feature_5_sec_nMFCC_nht_ys_yat.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "490b88d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Feature Dataset with 4 classes & Sample Duration: augmented sound signal (5 seconds): (based dataset to use:DS_1_Feature_MFCC_hilbert_trans_ms_1sec.csv)\n",
    "# 1.         Hilbert Transformed - Yes, MFCC included: Yes , Scale Data: No, Anomaly treated: No\n",
    "base_df = pd.read_csv(\"Data\\DS_1_Feature_MFCC_hilbert_trans_ms_1sec.csv\")\n",
    "base_df,col_ignored = eliminate_irrelevant_columns_in_dataset(base_df)\n",
    "base_df.to_csv(\"Data\\Model Datasets\\DS_1_All_Feature_1_sec_yMFCC_yht_ns_nat.csv\", index=False)\n",
    "\n",
    "# # 2.         Hilbert Transformed - Yes, MFCC included: Yes , Scale Data: No, Anomaly treated: Yes\n",
    "anomaly_df = treat_anomaly(base_df)\n",
    "anomaly_df,col_ignored = eliminate_irrelevant_columns_in_dataset(anomaly_df)\n",
    "anomaly_df.to_csv(\"Data\\Model Datasets\\DS_1_All_Feature_1_sec_yMFCC_yht_ns_yat.csv\", index=False)\n",
    "\n",
    "# 3.         Hilbert Transformed - Yes, MFCC included: Yes ,  Scale Data: Yes, Anomaly treated: No\n",
    "scaled_df = scale_dataset(base_df)\n",
    "scaled_df,col_ignored = eliminate_irrelevant_columns_in_dataset(scaled_df)\n",
    "scaled_df.to_csv(\"Data\\Model Datasets\\DS_1_All_Feature_1_sec_yMFCC_yht_ys_nat.csv\", index=False)\n",
    "\n",
    "# # 4.         Hilbert Transformed - Yes, MFCC included: Yes , Scale Data: Yes, Anomaly treated: Yes\n",
    "scaled_df = scale_dataset(base_df)\n",
    "anomaly_df = treat_anomaly(scaled_df)\n",
    "anomaly_df,col_ignored = eliminate_irrelevant_columns_in_dataset(anomaly_df)\n",
    "anomaly_df.to_csv(\"Data\\Model Datasets\\DS_1_All_Feature_1_sec_yMFCC_yht_ys_yat.csv\", index=False)\n",
    "\n",
    "# 5.         Hilbert Transformed - Yes, MFCC included: No ,  Scale Data: No, Anomaly treated: No\n",
    "no_mfcc_base_df = ignore_columns_in_dataset(base_df,str_pattern=\"mfcc_\")\n",
    "no_mfcc_df,col_ignored = eliminate_irrelevant_columns_in_dataset(no_mfcc_base_df)\n",
    "no_mfcc_df.to_csv(\"Data\\Model Datasets\\DS_1_All_Feature_1_sec_nMFCC_yht_ns_nat.csv\", index=False)\n",
    "\n",
    "# 6.         Hilbert Transformed - Yes, MFCC included: No ,  Scale Data: Yes, Anomaly treated: No\n",
    "scaled_df = scale_dataset(no_mfcc_base_df)\n",
    "scaled_df,col_ignored = eliminate_irrelevant_columns_in_dataset(scaled_df)\n",
    "scaled_df.to_csv(\"Data\\Model Datasets\\DS_1_All_Feature_1_sec_nMFCC_yht_ys_nat.csv\", index=False)\n",
    "\n",
    "# 7.         Hilbert Transformed - Yes, MFCC included: No ,  Scale Data: No, Anomaly treated: Yes\n",
    "anomaly_df = treat_anomaly(no_mfcc_base_df)\n",
    "anomaly_df,col_ignored = eliminate_irrelevant_columns_in_dataset(anomaly_df)\n",
    "anomaly_df.to_csv(\"Data\\Model Datasets\\DS_1_All_Feature_1_sec_nMFCC_yht_ns_yat.csv\", index=False)\n",
    "\n",
    "# 8.         Hilbert Transformed - Yes, MFCC included: No ,  Scale Data: Yes, Anomaly treated: Yes\n",
    "scaled_df = scale_dataset(no_mfcc_base_df)\n",
    "anomaly_df = treat_anomaly(scaled_df)\n",
    "anomaly_df,col_ignored = eliminate_irrelevant_columns_in_dataset(anomaly_df)\n",
    "anomaly_df.to_csv(\"Data\\Model Datasets\\DS_1_All_Feature_1_sec_nMFCC_yht_ys_yat.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bb1df49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Feature Dataset with 4 classes & Sample Duration: augmented sound signal (5 seconds): (based dataset to use:DS_1_Feature_MFCC_no_hilbert_trans_ms_1sec.csv)\n",
    "# 1.         Hilbert Transformed - No, MFCC included: Yes , Scale Data: No, Anomaly treated: No\n",
    "base_df = pd.read_csv(\"Data\\DS_1_Feature_MFCC_no_hilbert_trans_ms_1sec.csv\")\n",
    "base_df,col_ignored = eliminate_irrelevant_columns_in_dataset(base_df)\n",
    "base_df.to_csv(\"Data\\Model Datasets\\DS_1_All_Feature_1_sec_yMFCC_nht_ns_nat.csv\", index=False)\n",
    "\n",
    "# # 2.         Hilbert Transformed - No, MFCC included: Yes , Scale Data: No, Anomaly treated: Yes\n",
    "anomaly_df = treat_anomaly(base_df)\n",
    "anomaly_df,col_ignored = eliminate_irrelevant_columns_in_dataset(anomaly_df)\n",
    "anomaly_df.to_csv(\"Data\\Model Datasets\\DS_1_All_Feature_1_sec_yMFCC_nht_ns_yat.csv\", index=False)\n",
    "\n",
    "# 3.         Hilbert Transformed - No, MFCC included: Yes ,  Scale Data: Yes, Anomaly treated: No\n",
    "scaled_df = scale_dataset(base_df)\n",
    "scaled_df,col_ignored = eliminate_irrelevant_columns_in_dataset(scaled_df)\n",
    "scaled_df.to_csv(\"Data\\Model Datasets\\DS_1_All_Feature_1_sec_yMFCC_nht_ys_nat.csv\", index=False)\n",
    "\n",
    "# # 4.         Hilbert Transformed - No, MFCC included: Yes , Scale Data: Yes, Anomaly treated: Yes\n",
    "scaled_df = scale_dataset(base_df)\n",
    "anomaly_df = treat_anomaly(scaled_df)\n",
    "anomaly_df,col_ignored = eliminate_irrelevant_columns_in_dataset(anomaly_df)\n",
    "anomaly_df.to_csv(\"Data\\Model Datasets\\DS_1_All_Feature_1_sec_yMFCC_nht_ys_yat.csv\", index=False)\n",
    "\n",
    "# 5.         Hilbert Transformed - No, MFCC included: No ,  Scale Data: No, Anomaly treated: No\n",
    "no_mfcc_base_df = ignore_columns_in_dataset(base_df,str_pattern=\"mfcc_\")\n",
    "no_mfcc_df,col_ignored = eliminate_irrelevant_columns_in_dataset(no_mfcc_base_df)\n",
    "no_mfcc_df.to_csv(\"Data\\Model Datasets\\DS_1_All_Feature_1_sec_nMFCC_nht_ns_nat.csv\", index=False)\n",
    "\n",
    "# 6.         Hilbert Transformed - No, MFCC included: No ,  Scale Data: Yes, Anomaly treated: No\n",
    "scaled_df = scale_dataset(no_mfcc_base_df)\n",
    "scaled_df,col_ignored = eliminate_irrelevant_columns_in_dataset(scaled_df)\n",
    "scaled_df.to_csv(\"Data\\Model Datasets\\DS_1_All_Feature_1_sec_nMFCC_nht_ys_nat.csv\", index=False)\n",
    "\n",
    "# 7.         Hilbert Transformed - No, MFCC included: No ,  Scale Data: No, Anomaly treated: Yes\n",
    "anomaly_df = treat_anomaly(no_mfcc_base_df)\n",
    "anomaly_df,col_ignored = eliminate_irrelevant_columns_in_dataset(anomaly_df)\n",
    "anomaly_df.to_csv(\"Data\\Model Datasets\\DS_1_All_Feature_1_sec_nMFCC_nht_ns_yat.csv\", index=False)\n",
    "\n",
    "# 8.         Hilbert Transformed - No, MFCC included: No ,  Scale Data: Yes, Anomaly treated: Yes\n",
    "scaled_df = scale_dataset(no_mfcc_base_df)\n",
    "anomaly_df = treat_anomaly(scaled_df)\n",
    "anomaly_df,col_ignored = eliminate_irrelevant_columns_in_dataset(anomaly_df)\n",
    "anomaly_df.to_csv(\"Data\\Model Datasets\\DS_1_All_Feature_1_sec_nMFCC_nht_ys_yat.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c40616",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
