{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d7e0034",
   "metadata": {},
   "source": [
    "This script succeeds DS_1_Generate_Dataset_for_Analysis.py and performs the GridSearch using cross validation on AdaBoost model to determine the optimal parameters of AdaBoost associated with each dataset with accuracy as the metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ded7a712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modelling algorithm\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Model selection\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, GridSearchCV, cross_val_score\n",
    "\n",
    "#metrics\n",
    "from sklearn.metrics import roc_curve,auc,accuracy_score, roc_auc_score, f1_score\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58671bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindOptimalParm(X,y):    \n",
    "    # Adaboost classifiers - find the optimal parameters using unscaled raw data \n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,stratify=y)\n",
    "\n",
    "    gs_parm_grid = {'n_estimators':[100,200,500,800,1000,1500],\n",
    "                   'learning_rate':[0.01,0.05,0.1,0.2,0.3]}\n",
    "    ab_clf = AdaBoostClassifier()\n",
    "    cv_model = RepeatedStratifiedKFold(n_splits = 5, n_repeats=1,random_state=1)\n",
    "    grid_search_model_raw = GridSearchCV(estimator = ab_clf, \n",
    "                                     param_grid = gs_parm_grid, \n",
    "                                     n_jobs=1,\n",
    "                                     cv=cv_model, \n",
    "                                     scoring = 'accuracy',\n",
    "                                     verbose = 2)\n",
    "\n",
    "    grid_search_score_raw = grid_search_model_raw.fit(X,y)\n",
    "\n",
    "    # cv_scores = cross_val_score(ab_clf, X,y,scoring='accuracy',cv=cv_model,n_jobs=1,error_score='raise')\n",
    "\n",
    "    # print('Accuracy: %.3f (%.3f)' % (np.mean(cv_scores), np.std(cv_scores)))\n",
    "\n",
    "    print(grid_search_score_raw)\n",
    "    print(\"Best scores:\")\n",
    "    print(\"Best: %f using %s\" % (grid_search_score_raw.best_score_, grid_search_score_raw.best_params_))\n",
    "    return grid_search_score_raw.best_score_, grid_search_score_raw.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c10b291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\\Model Datasets\\DS_1_All_Feature_1_sec_nMFCC_nht_ns_nat.csv\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=100; total time= 1.8min\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=100; total time= 1.8min\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=100; total time= 1.8min\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=100; total time= 2.0min\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=100; total time= 1.8min\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=200; total time= 3.6min\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=200; total time= 3.7min\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=200; total time= 3.6min\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=200; total time= 3.5min\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=200; total time= 3.6min\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time= 9.0min\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time= 9.4min\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time= 9.4min\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time= 9.4min\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time= 9.2min\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=800; total time=14.6min\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=800; total time=15.3min\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=800; total time=14.6min\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=800; total time=14.7min\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=800; total time=15.1min\n"
     ]
    }
   ],
   "source": [
    "\n",
    "root_path = \"Data\\Model Datasets\"\n",
    "cntr_val = 0\n",
    "for file_name in os.scandir(root_path):\n",
    "    if cntr_val >=1:\n",
    "        break\n",
    "    file_path = file_name.path\n",
    "    print(file_path)\n",
    "    dataset_df = pd.read_csv(file_path)\n",
    "    db_row = {'File Name':[file_path]}\n",
    "    \n",
    "    num_classes = len(set(list(dataset_df.sound_file_class)))\n",
    "    db_row = db_row | {'# classes':[num_classes]}\n",
    "\n",
    "    data_size = int(dataset_df.shape[0])\n",
    "    db_row = db_row | {'N':[data_size]}\n",
    "\n",
    "    data_size = int(dataset_df.shape[1])\n",
    "    db_row = db_row | {'# features':[data_size]}\n",
    "    \n",
    "    hilbert_flag = \"Yes\"\n",
    "    if \"_nht\" in file_path:\n",
    "        hilbert_flag = \"No\"\n",
    "\n",
    "    db_row = db_row | {'Hilbert Transformed?':[hilbert_flag]}\n",
    "\n",
    "    mfcc_flag = \"Yes\"\n",
    "    if \"_nMFCC\" in file_path:\n",
    "        mfcc_flag = \"No\"\n",
    "\n",
    "    db_row = db_row | {'MFCC included?':[mfcc_flag]}\n",
    "\n",
    "    sample_dur = \"30 seconds\"\n",
    "    if \"_5_sec\" in file_path:\n",
    "        sample_dur = \"30 seconds\"\n",
    "    elif \"_1_sec\" in file_path:\n",
    "        sample_dur = \"1 second\"\n",
    "\n",
    "    db_row = db_row | {'Sample Duration':[sample_dur]}\n",
    "\n",
    "    scaled_flag = \"Yes\"\n",
    "    if \"_ns\" in file_path:\n",
    "        scaled_flag = \"No\"\n",
    "    \n",
    "    db_row = db_row | {'Data Scaled?':[scaled_flag]}\n",
    "    \n",
    "    anomaly_flag = \"Yes\"\n",
    "    if \"_nat\" in file_path:\n",
    "        anomaly_flag = \"No\"\n",
    "    \n",
    "    db_row = db_row | {'Anomaly Treated?':[anomaly_flag]}\n",
    "    \n",
    "    # Determine the optimal parameters\n",
    "    \n",
    "    #1. Convert the sound_file_class label into a ordinal variable \n",
    "    X_raw = dataset_df\n",
    "    X_raw['sound_file_class_num'] = X_raw.apply(lambda x: 1 if x.sound_file_class=='Q1' \n",
    "                                                        else (2 if x.sound_file_class=='Q2' \n",
    "                                                              else (3 if x.sound_file_class=='Q3' else 4)), axis=1)\n",
    "\n",
    "    X = X_raw[X_raw.columns[~X_raw.columns.isin(['sound_file_name', 'sound_file_class','sound_file_class_num'])]]\n",
    "    #print(list(X.columns))\n",
    "    y,unique_vals = pd.factorize(X_raw['sound_file_class_num'], sort=True)\n",
    "    \n",
    "    best_score, best_parms = FindOptimalParm(X,y)\n",
    "    data_df = pd.DataFrame(db_row)\n",
    "\n",
    "    # Build feature dataset\n",
    "    if cntr_val == 0:\n",
    "        final_df = data_df\n",
    "        #break\n",
    "    else:\n",
    "        final_df = pd.concat([final_df,data_df],axis=0)\n",
    "    cntr_val +=1\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37f0596",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
